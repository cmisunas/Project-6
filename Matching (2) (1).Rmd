---
title: "Project 6"
author: "Chris, Christina, and Juana"
date: "2023-04-07"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Libraries
```{r}
library(tidyverse)  #contains dplyr, ggplot2, and purr 
library(MatchIt)
library(optmatch)
library(cobalt)
library(marginaleffects)
library(magrittr)
library(data.table)
```

#Data
```{r}
df2 <- read_csv('data/ypsps.csv')
head(ypsps)
```
# 3.
### Randomly assign treatment and control to a vector called "treat_vec"
```{r}
set.seed(123) 
n <- 1254 
treat_prop <- 0.5 
df2$treat_vec <- sample(c("treatment", "control"), size = n, prob = c(treat_prop, 1-treat_prop), replace = TRUE)
```

### Looking at a covariate...parents' employment
```{r}
table(df2$parent_Employ)
```

### Looking at covariate distriution, comparing those in treatment and those in control
```{r}
employ_treat <- table(df2$parent_Employ, df2$treat_vec)
barplot(employ_treat, main = "Distribution of Parents' Employment by Treatment Assignment", xlab = "Employment", col = c("blue", "red"), border = "white", legend = TRUE)
```

The bar plot above clearly shows very little difference in the distribution of parents' employment among the two groups; this is also confirmed by the large p-value from the $\chi^2$ test.

```{r}
chisq.test(table(df2$parent_Employ, df2$treat_vec))
```

```{r}
results <- rep(NA, 10000)
for(i in 1:10000){
   df2$treat_vec = sample(c("treatment", "control"), size = n, prob = c(0.5, 0.5), replace = T)
   t <-df2 %>% 
     group_by(parent_Employ,treat_vec) %>% 
     mutate(n=n()) %>% 
     group_by(treat_vec) %>% 
     distinct(treat_vec,parent_Employ,n)%>%
     mutate(Per=n/sum(n), np= (round(Per*100,2))) %>%
     select(-n,-Per) %>% 
     spread(treat_vec,np)
    t
    a <- t[1,3]
    results[i] <-a
}
as.numeric(results)
```

## Question 3.1.
Question 3.1. On visual inspection, the distribution of proportions of parental employment appears to be balanced across the treatment and control arms after our 10,000 simulations. However, this does not necessarily guarantee balance of treatment assignment and baseline covariates. For example, although we perceive the treatment and control arms as being balanced by our exposure variable (in our case, college attendance), it is possible that when we take into consideration other important covariates, the distribution is imbalanced. 




# 4. Propensity Score Matching

## 4.1 One Model

### Select covariates that represent the "true" model for selection, fit model

```{r}
df_set<- subset(ypsps, 
                select = c(interviewid,
                          student_ppnscal,
                          college,
                          student_vote,
                          student_GPA,
                          student_Gen,
                          student_Race,
                          student_PID,
                          student_Knowledge,
                          parent_Vote,
                          parent_Persuade,
                          parent_Employ,
                          parent_EducHH,
                          parent_FInc,
                          parent_PID,
                          parent_Knowledge))

covs <- subset(df_set, select = -c(interviewid,college,student_ppnscal))

```

```{r}
table(df_set$college)
```


```{r}
model_ps <- glm(college ~ student_vote + student_GPA + student_Gen + student_Race +  student_PID + student_Knowledge + parent_Persuade + parent_Employ + parent_EducHH + parent_FInc + parent_PID + parent_Knowledge, family = binomial(), data = df_set)
summary(model_ps)
```

### Calculate Propensity Score
```{r}
df_set <- df_set %>% mutate(prop_score = predict(model_ps))
```



# Perform full matching on the propensity score for the ATT

```{r}
match_opt_att <- matchit(formula = college ~ student_vote + student_GPA + student_Gen + student_Race +  student_PID + student_Knowledge + parent_Persuade + parent_Employ + parent_EducHH + parent_FInc + parent_PID + parent_Knowledge, data = df_set, method = "nearest", estimand = "ATT")
summary(match_opt_att, un = FALSE)

#Extract matched data
match_opt_att_data <- match.data(match_opt_att)


#Run the original model ppmscal-> outcome
lm_opt_att <- lm(student_ppnscal ~ college + student_vote + student_GPA + student_Gen + student_Race +  student_PID + student_Knowledge + parent_Persuade + parent_Employ + parent_EducHH + parent_FInc + parent_PID + parent_Knowledge, data = match_opt_att_data, weights = weights)
lm_opt_att_summ <- summary(lm_opt_att)
lm_opt_att_summ
```
```{r}
ATT_opt <- lm_opt_att_summ$coefficients["college","Estimate"]
ATT_opt
```


```{r}
avg_comparisons(lm_opt_att, variables = "college",
                vcov = ~student_vote + student_GPA + student_Gen + student_Race +  
                  student_PID + student_Knowledge + parent_Persuade + parent_Employ +
                  parent_EducHH + parent_FInc + parent_PID + parent_Knowledge,
                newdata = subset(match_opt_att_data, A == 1),
                wts = "weights")
```


# Plot the balance for the top 10 covariates

#### Distribution balance for some covariates

```{r}
m.out <- MatchIt::matchit(college ~ student_vote + student_GPA + student_Gen + student_Race + 
                            student_PID + student_Knowledge + parent_Persuade + parent_Employ + 
                            parent_EducHH + parent_FInc + parent_PID + parent_Knowledge, 
                          data = df_set, method = "nearest",  replace = TRUE)
```

```{r}
bal.plot(m.out,var.name="student_vote")
```
#### Covariate balance


```{r}
love.plot(m.out, binary = "std", thresholds = c(m = .1))
```
```{r}
bal.tab(m.out,binary = "std")
```
#### Report the number of covariates that meet a threshold of standardized mean difference of p-score <= .1
```{r}
bal.tab(m.out, binary = "std", thresholds = .1)


```
#### Distribution balance for some not balance covariates
```{r}
bal.plot(m.out,var.name="student_GPA")
```
```{r}
bal.plot(m.out,var.name="student_Gen")
```
```{r}
bal.plot(m.out,var.name="parent_Employ")
```
## 4.2 Simulations
### Remove post-treatment covariates
```{r}
ls(ypsps)
```

```{r}
df_new <- subset(ypsps, select = -c(student_1982communicate,
                                    student_1982community,
                                    student_1982demonstrate,
                                    student_1982HHInc, 
                                    student_1982IncSelf,
                                    student_1982meeting,   
                                    student_1982money,  
                                    student_1982other,
                                    student_1982vote76,
                                    student_1982vote80,
                                    student_1973CollegeDegree,
                                    student_1973CollegeYears,
                                    student_1973CurrentCollege,
                                    student_1973CurrentSituation,
                                    student_1973Drafted,
                                    student_1973FutureSituation, 
                                    student_1973GovChange,
                                    student_1973GovtEfficacy,
                                    student_1973GovtNoSay,
                                    student_1973HelpMinority,
                                    student_1973HHInc,
                                    student_1973Ideology,        
     student_1973IncSelf,             student_1973Knowledge,                  student_1973Luck,             student_1973Married,       
    student_1973Military,             student_1973Newspaper,           student_1973NoEmployers,      student_1973NoResidences,   
     student_1973OwnHome,               student_1973PartyID,            student_1973PubAffairs,       student_1973SureAboutLife,   
  student_1973ThermBlack,             student_1973ThermDems,         student_1973ThermMcgovern,    student_1973ThermMilitary, 
  student_1973ThermNixon,          student_1973ThermRadical,              student_1973ThermRep,         student_1973ThermWhite,      
       student_1973Trust,            student_1973Unemployed,        student_1973VietnamApprove,   student_1973VietnamRight, 
student_1973VoteMcgovern,             student_1973VoteNixon,                student_1982button,           student_1982College,interviewid,student_1973Busing,parent_GPHighSchoolPlacebo, parent_HHCollegePlacebo,student_1973ChurchAttend ))

covariates_new<-subset(df_new, select = -c(college))
```


### Randomly select features
```{r}
# create a random set of column indexes
indexes <- sample(ncol(df_new), 3)

# select random columns from the original data set
df_sample <- df_new[, indexes]
```


### Simulate random selection of features 10k+ times

```{r}
#Create empty vectors
ATT_list<- NULL
prop_covs_threshold<- NULL 
mean_improvement<-NULL
model <- NULL


for (i in 1:1000) {

### Fit p-score models and save ATTs, proportion of balanced covariates, and mean percent balance improvement
  
# randomly select the number of covariates
n_covariates <- sample(1:118, 1)

# randomly select the covariates
selected_covariates <- sample(colnames(covariates_new), n_covariates)

# create the propensity score model formula
ps_formula <- as.formula(paste("college ~", paste(selected_covariates, collapse = " + ")))

# fit the propensity score model for ATT
match_att <- matchit(formula = ps_formula, data = df_new, method = "nearest", estimand = "ATT")
summary(match_att, un = FALSE)

#Extract matched data
match_att_data <- match.data(match_att)

#formula for complete model

ps_formula_model <- as.formula(paste("student_ppnscal ~ college +", paste(selected_covariates, collapse = " + ")))

#Run the original model ppmscal-> outcome

lm_att <- lm(ps_formula_model, data = match_att_data, weights = weights)
lm_att_summ <- summary(lm_att)
lm_att_summ
ATT <- lm_att_summ$coefficients["college","Estimate"]
ATT

m.out <- MatchIt::matchit(ps_formula, 
                          data = df_new, 
                          method = "nearest",  replace = TRUE)

TAB<-bal.tab(m.out, binary = "std", thresholds = .1)
PROP<- TAB$Balanced.mean.diffs/sum(TAB$Balanced.mean.diffs)


pre <- data.frame(summary(m.out)$sum.all) %>%
  pull(Std..Mean.Diff.) %>%
  mean()
post <- data.frame(summary(m.out)$sum.matched) %>%
  pull(Std..Mean.Diff.) %>%
  mean()
percent_imp <- (post - pre) / pre

ATT_list[i] <-  ATT
prop_covs_threshold[i]<- PROP[1,1]
mean_improvement[i]<- percent_imp
}

ATT_list
prop_covs_threshold
mean_improvement

dp<-as.data.frame(cbind(ATT_list, prop_covs_threshold,mean_improvement))

```
```{r}
hist(ATT_list)
```

### Plot ATT v. proportion

```{r}
pg <- ggplot(data = dp,aes(ATT_list,prop_covs_threshold)) + geom_point(shape = 2) 
    
print(pg)
```

## Question 4.1

Of the 100 simulations that we ran 124 were above the threshold of .75 and 206 were below .3. Simulations with the higher percent of balanced covariates tend to have a stronger ATT. Our only concern would be that low balanced covariates are more like in this dataset even after the simulations. 

## Question 4.2

The distribution of the ATT's range from -0.12 to 2.755 and skew towards 0. Our concern is that it's hard to come to a conclusion about the ATT with such a skewed distribution and a higher propensity of higher inbalanced covariates.


# 5. Propensity Score Matching

## 5.1 Simulation

```{r}
#Create empty vectors
ATT_list2<- NULL
prop_covs_threshold2<- NULL 
mean_improvement2<-NULL
model2 <- NULL


for (i in 1:1000) {

### Fit p-score models and save ATTs, proportion of balanced covariates, and mean percent balance improvement
  
# randomly select the number of covariates
n_covariates <- sample(1:118, 1)

# randomly select the covariates
selected_covariates <- sample(colnames(covariates_new), n_covariates)

# create the propensity score model formula
ps_formula <- as.formula(paste("college ~", paste(selected_covariates, collapse = " + ")))

# fit the propensity score model for ATT
match_att <- matchit(formula = ps_formula, data = df_new, method = "optimal", estimand = "ATT")
summary(match_att, un = FALSE)

#Extract matched data
match_att_data <- match.data(match_att)

#formula for complete model

ps_formula_model <- as.formula(paste("student_ppnscal ~ college +", paste(selected_covariates, collapse = " + ")))

#Run the original model ppmscal-> outcome

lm_att <- lm(ps_formula_model, data = match_att_data, weights = weights)
lm_att_summ <- summary(lm_att)
lm_att_summ
ATT <- lm_att_summ$coefficients["college","Estimate"]
ATT

m.out <- MatchIt::matchit(ps_formula, 
                          data = df_new, 
                          method = "optimal",  replace = TRUE)

TAB<-bal.tab(m.out, binary = "std", thresholds = .1)
PROP<- TAB$Balanced.mean.diffs/sum(TAB$Balanced.mean.diffs)


pre <- data.frame(summary(m.out)$sum.all) %>%
  pull(Std..Mean.Diff.) %>%
  mean()
post <- data.frame(summary(m.out)$sum.matched) %>%
  pull(Std..Mean.Diff.) %>%
  mean()
percent_imp <- (post - pre) / pre

ATT_list2[i] <-  ATT
prop_covs_threshold2[i]<- PROP[1,1]
mean_improvement2[i]<- percent_imp
}

ATT_list2
prop_covs_threshold2
mean_improvement2

dp2<-as.data.frame(cbind(ATT_list2, prop_covs_threshold2,mean_improvement2))

```


```{r}
hist(ATT_list_2)
```

### Plot ATT v. proportion

```{r}
pg_2 <- ggplot(data = dp_2,aes(ATT_list_2,prop_covs_threshold2)) + geom_point(shape = 2) 
    
print(pg_2)
```

## Question 5.1.

Yes, we see that simulations with "optimal" matching tend to have higher proportions of balanced covariates. 

# 6.
## Question 6.1
Even if we have a randomized or as-if-random design, it is a good idea to use matching because there may be important covariates that are not balanced across the different arms despite randomization.  

## Question 6.2
Given what we know about the curse of dimensionality, machine learning algorithms might be a good alternative to estimating propensity scores because these techqniues would enable us to account for many covariates. 
